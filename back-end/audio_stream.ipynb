{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade google-cloud-speech PyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "import re\n",
    "\n",
    "import pyaudio\n",
    "\n",
    "\n",
    "class MicrophoneStream:\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "\n",
    "    def __init__(self: object, rate: int = RATE, chunk: int = CHUNK) -> None:\n",
    "        \"\"\"The audio -- and generator -- is guaranteed to be on the main thread.\"\"\"\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "\n",
    "        # Create a thread-safe buffer of audio data\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    def __enter__(self: object) -> object:\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=1,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self._chunk,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(\n",
    "        self: object,\n",
    "        type: object,\n",
    "        value: object,\n",
    "        traceback: object,\n",
    "    ) -> None:\n",
    "        \"\"\"Closes the stream, regardless of whether the connection was lost or not.\"\"\"\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(\n",
    "        self: object,\n",
    "        in_data: object,\n",
    "        frame_count: int,\n",
    "        time_info: object,\n",
    "        status_flags: object,\n",
    "    ) -> object:\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\n",
    "\n",
    "        Args:\n",
    "            in_data: The audio data as a bytes object\n",
    "            frame_count: The number of frames captured\n",
    "            time_info: The time information\n",
    "            status_flags: The status flags\n",
    "\n",
    "        Returns:\n",
    "            The audio data as a bytes object\n",
    "        \"\"\"\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self: object) -> object:\n",
    "        \"\"\"Generates audio chunks from the stream of audio data in chunks.\n",
    "\n",
    "        Args:\n",
    "            self: The MicrophoneStream object\n",
    "\n",
    "        Returns:\n",
    "            A generator that outputs audio chunks.\n",
    "        \"\"\"\n",
    "        while not self.closed:\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b\"\".join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of single utterance detected\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from google.cloud import speech\n",
    "\n",
    "\n",
    "def listen_print_loop(responses: object) -> str:\n",
    "    \"\"\"Iterates through server responses and prints them.\"\"\"\n",
    "    num_chars_printed = 0\n",
    "    for response in responses:\n",
    "        # Check for the end-of-utterance event\n",
    "        if response.speech_event_type == speech.StreamingRecognizeResponse.SpeechEventType.END_OF_SINGLE_UTTERANCE:\n",
    "            print('End of single utterance detected')\n",
    "            break\n",
    "\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "        result = response.results[0]\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "\n",
    "        transcript = result.alternatives[0].transcript\n",
    "        overwrite_chars = \" \" * (num_chars_printed - len(transcript))\n",
    "\n",
    "        if not result.is_final:\n",
    "            sys.stdout.write(transcript + overwrite_chars + \"\\r\")\n",
    "            sys.stdout.flush()\n",
    "            num_chars_printed = len(transcript)\n",
    "        else:\n",
    "            print(transcript + overwrite_chars)\n",
    "            num_chars_printed = 0\n",
    "\n",
    "    return transcript\n",
    "\n",
    "\n",
    "\"\"\"Transcribe speech from audio file.\"\"\"\n",
    "language_code = \"en-US\"  # a BCP-47 language tag\n",
    "\n",
    "client = speech.SpeechClient()\n",
    "config = speech.RecognitionConfig(\n",
    "    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz=RATE,\n",
    "    language_code=language_code,\n",
    ")\n",
    "\n",
    "streaming_config = speech.StreamingRecognitionConfig(\n",
    "    config=config, \n",
    "    interim_results=True,\n",
    "    single_utterance=True\n",
    ")\n",
    "\n",
    "with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "    audio_generator = stream.generator()\n",
    "    requests = (\n",
    "        speech.StreamingRecognizeRequest(audio_content=content)\n",
    "        for content in audio_generator\n",
    "    )\n",
    "\n",
    "    responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "    # Now, put the transcription responses to use.\n",
    "    transcript = listen_print_loop(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going my name is Kellan\n"
     ]
    }
   ],
   "source": [
    "print(transcript)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
